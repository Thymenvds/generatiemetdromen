<!DOCTYPE html>
<html lang="nl-be">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <base href="/">
  <title>Generatie Met Dromen - EU AI Act</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Funnel+Display:wght@300..800&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200&icon_names=menu" />
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
  <link rel="stylesheet" href="style.css">
  <link rel="stylesheet" href="blog/style.css">
  <link rel="icon" type="image/x-icon" href="assets/favicon_io/favicon.ico">
  <link rel="apple-touch-icon" sizes="180x180" href="assets/favicon_io/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="assets/favicon_io/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="assets/favicon_io/favicon-16x16.png">
  <link rel="manifest" href="assets/favicon_io/site.webmanifest">
  <style>
  @media screen and (min-width: 900px){
    .vis_destkop{
      display: block;
    }
    .vis_gsm{
      display: none;
    }
    
  }
  @media screen and (max-width: 900px){
    .vis_destkop{
      display: none;
    }
    .vis_gsm{
      display: inline;
    }
  }

  </style>
</head>
<body>
  <nav class="navbar navbar-expand-lg">
    <div class="container-fluid">
      <a class="navbar-brand" href="#"><img src="assets/logo_text_green.png" alt="" height="48"></a>
      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="material-symbols-outlined">menu</span>
      </button>
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav me-auto mb-2 mb-lg-0">
          <li class="nav-item">
            <a class="nav-link" href="#missie">Missie</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="blog">Blog</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="#team">Ons team</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="#contact">Contact</a>
          </li>
      </div>
    </div>
  </nav>

  <div class="blog">
    <div style="margin-bottom: 20px;">
      <span class="author">Dante Van Poucke</span>&nbsp;&nbsp;&nbsp;&nbsp;
      <span class="thick-underline-hover">europese wetgeving</span>
      <span>&nbsp;&nbsp;&nbsp;&nbsp;</span>
      <em>7 mei 2025</em>
    </div>
    <h1 style="margin-bottom: 15px;">EU AI Act</h1>
    <p>
      Sinds juni vorig jaar pronkt de Europese Unie met haar AI Act.
      Europa is hiermee de eerste die op grote schaal regelgeving rond artificiële intelligentie invoert.
      Deze reguleert de ontwikkeling, inzet en het gebruik van kunstmatige intelligentie (AI) binnen de Europese Unie.
      Maar wat omvat deze AI-act nu precies?
      Hoe beschermt het onze menselijkheid en samenleving?
      Zullen we de impact hiervan voelen?
    </p> 
    <!-- <div style="display: flex; justify-content: center; margin-top: 35px; margin-bottom: 35px;">
    <img class="vis_destkop" src="assets/blog/sysprompt.png" width="95%" style="object-fit: cover;">
    <img class="vis_gsm" src="assets/blog/sysprompt_gsm.png" width="95%" style="object-fit: cover;">
    </div> -->
    <p>
      Op 12 juli 2024 publiceerde de EU “de verordening tot vaststelling van geharmoniseerde regels betreffende artificiële intelligentie”.
      De eerste fase hiervan trad in werking op 1 augustus, de laatste fase treed pas in werking op 1 augustus 2027.
      De AI act classificeert AI onder vier categorieën op basis van risico:
      <div style="display: flex; flex-direction: row; justify-content: space-evenly; justify-items: center; flex-wrap: wrap;">
        <div>
          <ol>
            <li>1.  Verboden AI systemen,</li>
            <li>2.  AI systemen met hoog risico,</li>
            <li>3.  AI systemen met beperkt risico,</li>
            <li>4.	AI systemen met minimaal risico.</li>
          </ol>
        </div>
        <img src="assets/blog/ai_act_pyramid.png" alt="">
      </div>
    </p>
    <p>
      Deze opdeling wordt gemaakt op basis van het toepassingsgebied van de AI systemen en niet op basis van de complexiteit ervan.
      Zo wordt bijvoorbeeld elk AI systeem dat gebruikt wordt om sociale scores te berekenen van mensen als verboden geclassificeerd.
    </p>
    <p>
      AI systemen die in de eerste categorie vallen zijn, zoals de naam doet vermoeden, volstrekt verboden binnen de grenzen van de EU.
      Aan de andere kant van het spectrum, zijn systemen met minimaal risico compleet ongereguleerd.
      Wanneer het gaat om een beperkt risico is, wordt een transparantie verplichting opgelegd: het moet voor eindgebruikers duidelijk zijn dat ze met AI aan het interageren is.
      De focus van de AI act ligt op de AI systemen met hoog risico.
    </p>
    <h4>Verboden AI-systemen</h4>
    <p>
      AI-systemen die als verboden worden beschouwd, zijn volledig uitgesloten binnen de EU.
      Dit omvat systemen die gebruikmaken van subliminale, manipulatieve of misleidende technieken om gedrag te beïnvloeden en geïnformeerde besluitvorming te verstoren, wat aanzienlijke schade kan toebrengen.
      Ook systemen die kwetsbaarheden benutten die te maken hebben met leeftijd, handicap of sociaaleconomische omstandigheden om gedrag te beïnvloeden, vallen onder deze categorie.
      Een voorbeeld hiervan is elk AI-systeem dat wordt ingezet om sociale scores van mensen te berekenen.
    </p>
    <h4>AI-systemen met hoog risico</h4>
    <p>
      De AI Act richt zich op AI-systemen die als hoog risico worden beschouwd.
      Deze systemen moeten voldoen aan strenge regels en verschillende verplichtingen.
      Ontwikkelaars zijn verplicht om een risicobeheersysteem op te zetten dat helpt bij het identificeren en aanpakken van mogelijke risico's.
      Ook is het cruciaal om gegevens te beschermen en de integriteit ervan te waarborgen.
      Daarnaast moet men een gedetailleerde technische documentatie bijhouden om aan te tonen dat men zich aan de regels houdt wat een active actie vereist van de producent.
      Bovendien moeten eindgebruikers op de hoogte worden gesteld dat ze met een AI-systeem werken, en moeten er mechanismen zijn om menselijk toezicht te garanderen en in te grijpen waar nodig. 
    </p>
    <h4>AI-systemen met beperkt risico</h4>
    <p>
      Voor AI-systemen met beperkt risico gelden lichtere transparantieverplichtingen.
      Ontwikkelaars en gebruikers moeten ervoor zorgen dat eindgebruikers zich ervan bewust zijn dat ze met een AI-systeem interageren.
      Dit geldt bijvoorbeeld voor chatbots en deepfakes.
    </p>
    <h4>AI-systemen met minimaal risico</h4>
    <p>
      AI-systemen met minimaal risico zijn grotendeels ongereguleerd.
      Voorbeelden hiervan zijn AI-gestuurde videogames en spamfilters.
      De meeste AI-toepassingen die momenteel op de EU-markt beschikbaar zijn, vallen in deze categorie.
    </p>
    <h4>Algemene trend</h4>
    <p>
      De EU legt de nadruk op het doel van de applicatie voor de indeling van het risico en niet de intelligentie van het systeem.
      In andere woorden, als er een tool gemaakt wordt die het verbeteren van examens automatiseert dan behoort deze tot een AI-systeem met een hoog risico ongeacht het onderling AI model de service gebruikt.
      Dit is een belangrijke nuance aangezien dit in een groot deel bepaalt wie de verantwoordelijkheid draagt in een AI product.
    </p>    
    <p>
      In de industrie worden AI modellen vaak gemaakt door grote bedrijven zoals Microsoft of Meta en maken jonge startups gebruik van de tools die deze tech giganten aanbieden.
      Een voorbeeld hiervan is een startup die het verbeteren van examens automatiseert.
      Dit bedrijf heeft nu een AI-systeem met een hoog risico ongeacht van het onderling AI model, (vaak geproduceerd door OpenAI, Meta, Microsoft, Google) dat men gebruikt.
      De EU legt in dit geval van de verantwoordelijkheid bij de startup.
      Deze keuze heeft zijn voor-en nadelen en de toekomst zal uitwijzen of dit voldoende is.
    </p>
    <p>
      De eindgebruiker heeft ook een verantwoordelijkheid in dit verhaal.
      Op dit moment heb je de mogelijkheid als leerkracht om een toets of examen te laten verbeteren door een AI chatbot als chatGPT.
      Dit is illegaal aangezien het valt onder een hoog risico AI-systeem.
      Wie heeft hier de verantwoordelijkheid?
      Deze bedrijven zetten hun product niet in de markt als een tool om examen te verbeteren maar ze maken het wel mogelijk.
      Moeten deze systemen de mogelijkheid verbieden om taken als deze uit te voeren of moeten ze standaard onder de categorie van hoog risico vallen? 
    </p>
    <h4>Vergelijking met AI-wetgeving in de rest van de wereld</h4>
    <p>
      De manier waarop AI-regelgeving wordt benaderd, verschilt enorm van regio tot regio.
      In de Verenigde Staten is het meer een verzameling van losse regels die per sector verschillen, zonder een overkoepelende federale wetgeving zoals de EU AI Act.
      In plaats daarvan zijn er richtlijnen die specifiek zijn voor sectoren zoals de gezondheidszorg en financiën.
      Toch heeft het National Institute of Standards and Technology (NIST) een AI Risk Management Framework ontwikkeld om richtlijnen te bieden voor het omgaan met AI-risico's.
    </p>
    <p>
      China daarentegen heeft in theorie een veel actievere aanpak als het gaat om AI-regelgeving.
      Ze hebben verschillende maatregelen en richtlijnen geïntroduceerd om de ontwikkeling en het gebruik van AI te reguleren.
      De Chinese overheid legt de nadruk op ethische normen en veiligheid, met strikte regels voor privacy en beveiliging.
      Bovendien zijn er specifieke regels voor bepaalde AI-toepassingen, zoals gezichtsherkenning en sociale kredietsystemen.
      Maar of deze regelgeving effectief uitgevoerd wordt kan valt te nog te zien.
    </p>
    <p>
      Canada volgt een meer op principes gebaseerde aanpak voor AI-regelgeving.
      De Canadese regering heeft de "Directive on Automated Decision-Making" geïntroduceerd, die richtlijnen biedt voor het gebruik van geautomatiseerde besluitvormingssystemen door overheidsinstanties.
      Deze richtlijn benadrukt het belang van transparantie, verantwoording en het minimaliseren van vooroordelen.
    </p>
    <h4>Conclusie</h4>
    <p>
      De EU AI Act is een wetgeving die een uitgebreid kader biedt voor het reguleren van AI-systemen, afhankelijk van hun toepassingsgebied en risico's.
      Het hoofddoel is om de mensheid en de samenleving te beschermen tegen mogelijke schade door AI, zonder innovatie en technologische vooruitgang tegen te gaan.
      De aanpak van de EU wijkt sterk af van die in andere delen van de wereld, waar de regelgeving vaak meer gefragmenteerd en gericht is op specifieke sectoren.
    </p>
    <p>
      Ben je zelf bezig met het ontwikkelen van een AI-systeem of wil je weten welke AI-systemen onder welke regels vallen?
      Neem dan eens een kijkje bij de <a href="https://artificialintelligenceact.eu/assessment/eu-ai-act-compliance-checker/">EU AI Act Compliance Checker</a> om te ontdekken hoe jouw AI-systeem geclassificeerd zou worden.
    </p>

  <hr>
  Heb je nog specifieke vragen over de EU AI Act of wil je meer weten over een bepaald aspect van de wetgeving?
  Laat het ons weten via onderstaand tekstvak (enkel te lezen door medewerkers van Generatie Met Dromen).
  
      <textarea id="feedback_bericht" style="height: 120px; width: 300px;" type="text" id="feedback" name="feedback" maxlength="1000" ></textarea>
    <div style="margin: 5px 0px 20px 0px">
      <button id="feedback_button">Verzenden</button>
    </div>
  
</div>
    

  <footer>
    <p>&copy; 2025 Generatie met Dromen</p>
    <p style="font-size: small;">Deze website samen met all inhoud is gemaakt zonder het gebruik van generatieve AI tenzij explicit vermeld.</p>
  </footer>

  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz" crossorigin="anonymous"></script>
  <script>
    function feedback(){
      let bericht_element = document.getElementById("feedback_bericht")
      let requestoptions = {
        method: 'POST',
  headers: {'Content-Type': 'application/json',},
  body: JSON.stringify(bericht_element.value),
      };
      fetch("/syspromtsfeedback", requestoptions)
      bericht_element.value=""
    };
    document.getElementById("feedback_button").addEventListener("click", feedback)
  </script>
</body>
</html>